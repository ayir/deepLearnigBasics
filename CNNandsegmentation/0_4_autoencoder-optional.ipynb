{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: Autoencoder (AE)\n",
    "================\n",
    "\n",
    "\n",
    "The Autoencoder is an important Neural Network architecture that can be trained unsupervised (no labels required) and can learn more sophisticated representations than linear Principle Component Analysis. \n",
    "Autoencoder are used for many applications such as:\n",
    "\n",
    "- Image compression\n",
    "- Feature learning\n",
    "- Image denoising or reconstruction\n",
    "- Unsupervised pretraining of Neural Networks\n",
    "\n",
    "An vanilla Autoencoder consists of an Encoder, a latent representation, and a Decoder. \n",
    "In this setup, the full resolution image is fed to the encoder that transforms the input into a lower dimensional latent representation vector. The dimensionality of the vector determine how much the initial information is compressed. Then, the decoder tries to reconstruct the initial image based on the latent representation vector. We train the network by comparing the reconstructed image to the original image and derive a loss from the difference. Therefore, we can train these networks without any supervision in the form of labels.\n",
    "\n",
    "The architecture of an autoencoder is demonstrated in the following image:\n",
    "![autoencoder.png](https://blog.keras.io/img/ae/autoencoder_schema.jpg)\n",
    "\n",
    "We can test an autoencoder, by taking a trained decoder and randomly sample a bottleneck vector. By feeding this vector into the network, we can generate \"new\" dataset examples.\n",
    "\n",
    "Goal of this notebook\n",
    "========\n",
    "\n",
    "By now, you always had a very structured notebook to follow. However, you will not have this luxury in your upcoming projects beyond this class. In order to deal with new tasks, it is important that you learn how to deal with new frameworks and data. To complete this notebook you have to:\n",
    "1. Deal with an unknown dataset.\n",
    "2. Learn how to use the pytorch dataloader class to efficiently manipulate your data and prepare it for training and testing\n",
    "3. Check out the pytorch neural network class.\n",
    "4. Write your own solver for a different task than classification.\n",
    "5. Understand the basic principles of Autoencoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#torch.set_default_tensor_type('torch.FloatTensor')\n",
    "#set up default cuda device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data: MNIST\n",
    "\n",
    "[MNIST](http://yann.lecun.com/exdb/mnist/), developed by Yann LeCun et al., is one of the oldest datasets around and is still used to get into machine learning. It contains grayscale images of single digit numbers of size `28x28x1` and was originally used for postal code classification.\n",
    "\n",
    "Don't forget to check out the dataset code from our current dataset, CIFAR10, which we provided in `data_utils.py` that you can find in the `exercise_code` folders of our exercise, to implement a similar pipeline for MNIST.\n",
    "\n",
    "Complete the following steps:\n",
    "1. Download the dataset either from the [official homepage](http://yann.lecun.com/exdb/mnist/) or any other source and try to load it into python so that you can print the contents as numpy arrays similar to how we started with the CIFAR10 dataset. As before, you should consider writing a dataset visualization.\n",
    "2. Use the official [documentation](http://pytorch.org/docs/data.html) to make yourself familiar with the `Dataset` class. It offers more sophisticated methods to load data which we don't require for MNIST but is a good practice for bigger datasets later on. Write a dataset class for your MNIST images and think about which transformations you would like to use.\n",
    "3. Use the `DataLoader` class to finish the data loader that we will use for training. It offers sampling and loading procedures which can easily be multithreaded.\n",
    "\n",
    "In the end, your dataloader should return an array of shape `(batch_size, 28, 28)` or similar that contains normalized values between `-1` and `1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Network: First Steps\n",
    "\n",
    "Please define your `class Autoencoder` as a `nn.Module` subclass and start with a simple linear implementation and use it to debug the solver class. Later on, move back to this step and refine the architecture, especially with a bottleneck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# Example: Autoencoder class with a single linear layer and no bottleneck  #\n",
    "############################################################################\n",
    "class AutoencoderModel(torch.nn.Module):\n",
    "    def __init__(self, shape=(28, 28)):\n",
    "        super(AutoencoderModel, self).__init__()\n",
    "        shape_prod = shape[0] * shape[1]\n",
    "        self.linear_layer = torch.nn.Linear(shape_prod, shape_prod)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # We assume that the input is of shape (batch_size, 28, 28) therefore\n",
    "        # we reshape the array to (batch_size, 28x28)\n",
    "        shape = input.size()\n",
    "        x = x.view(input.size(0), -1)\n",
    "        x = self.linear_layer(x)\n",
    "        # Reshape back to input size\n",
    "        x = x.view(*shape)\n",
    "        return x\n",
    "                       \n",
    "model = AutoencoderModel()\n",
    "############################################################################\n",
    "#                             END OF YOUR CODE                             #\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "1. Take one sample from the dataloader and feed it through the network. Visualize the input and output. The output will be random noise. (Optional: You can also check out if you can set the weights so that the linear layer above will be the identity.)\n",
    "2. Currently, the output can have any output values. Restrict the output of our network using a appropriate non-linearity so that they are again between `-1` and `1` as our data (see [pytorch layers for candidates or check out the lecture](https://pytorch.org/docs/stable/nn.html)).\n",
    "3. Go directly to the solver and code that up first. Afterwards you can come back to the network architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Autoencoder-Solver\n",
    "\n",
    "The solver should replicate the reconstruction autoencoder training procedure which is as follows:\n",
    "1. Take a random batch from the dataset.\n",
    "2. Feed it into our network.\n",
    "3. Compare the network output with the original batch.\n",
    "4. Backpropagate the error.\n",
    "\n",
    "We also want to evaluate the network performance on new data by computing the validation loss on our validation set.\n",
    "\n",
    "You will need to check out pytorch optimizers and look for some way to visualize your training with either the code we already written in the previous exercises or online with some additional libraries such as [tensorboardX](https://github.com/lanpa/tensorboardX)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function and accuracy\n",
    "As we want to compare our reconstructed image with the input, it is ill-advised to use crossentropy as our loss function. A more appropriate candidate would be a `L1 Loss` or something similar. You can check out the pytorch losses [here](https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html).\n",
    "\n",
    "By now we always used validation accuracy as our metric of choice. However, this no longer applies to our current situation as we are comparing images and accuracy does not represent our task as well as in classification. Therefore, we will only compare losses and there is no need to display accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solver tasks\n",
    "1. Network training procedure\n",
    "2. Sets optimizer and loss function\n",
    "3. Gives training visualization either online or offline after training using graphs\n",
    "4. Saves the trained network after training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test the pipeline\n",
    "\n",
    "1. Augment your dataloader so that it only returns a single image\n",
    "2. Run a training procedure to overfit the simple model from above using your new solver on this single image. This will make it very easy to debug your training procedure.\n",
    "\n",
    "Note: if you use the L1 loss, you won't be able to overfit completely. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Network: Autoencoder\n",
    "\n",
    "Now that we have a working solver, we can start with more sophisticated networks.\n",
    "\n",
    "1. Split up your single network into an encoder and a decoder. The encoder takes as input the original image and returns a smaller representation by decreasing the number of neurons at the last layer. The decoder takes this bootlneck input and returns a tensor of the form of the input.\n",
    "2. Overfit this network on a single test image.\n",
    "3. Train on the whole dataset.\n",
    "4. How small can you make the bottleneck while still being able to reconstruct the original image well enough?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test your network\n",
    "\n",
    "Now that we have a working autoencoder, we can test it by loading the decoder and take a random tensor of the shape of our bottleneck. We feed this random tensor into the decoder and it will present us with a \"new\" image of our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional:\n",
    "1. Do classification on MNIST\n",
    "2. Improve classification accuracy: take a smaller subset of MNIST, take your trained encoder, extend it to work as a classification network and compare to an untrained version of itself by training it on the smaller subset. During the autoencoder training it should have learned various features which make it very easy to learn using way less training images in comparison to a newly initialized network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merry Christmas and a happy new year!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
